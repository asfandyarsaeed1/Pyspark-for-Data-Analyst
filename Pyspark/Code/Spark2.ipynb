{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Selecting and Renaming Columns in SparkDataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://IT-130-21:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1a2efd0cf40>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "\n",
    "findspark.init()\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode_outer\n",
    "from pyspark.sql import Row\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr_Struct=[\n",
    "    {'id':1,\n",
    "     'name':\"asfand\",\n",
    "     'last': \"saeed\",\n",
    "     'is_customer':True,\n",
    "     'phone': Row(first=\"+92329677783\", Second=\"+92342454672\"),\n",
    "     'update': datetime.datetime(2022,4,12,4,10,0)\n",
    "    },\n",
    "    {'id':2,\n",
    "     'name':\"saeed\",\n",
    "     'last': \"asfand\",\n",
    "     'is_customer':True,\n",
    "     'phone': Row(first=\"+92329622283\", Second=\"+92342442312\"),\n",
    "     'update': datetime.datetime(2021,4,11,4,10,0)},\n",
    "    {'id':3,\n",
    "     'name':\"ali\",\n",
    "     'last':\"khan\",\n",
    "     'is_customer':False,\n",
    "     'phone': Row(first=\"+92329644483\", Second=\"+92342445552\"), ## Predefined structure as a Row\n",
    "     'update': datetime.datetime(2021,4,22,12,10,0)},\n",
    "    {'id':4,\n",
    "     'name':\"khan\",\n",
    "     'last':\"syed\",\n",
    "     'is_customer':False,\n",
    "     'phone': Row(first=None,Second=None),#['+92329633456','+9234247654'],\n",
    "     'update': None #datetime.datetime(2022,5,1,10,10,0)}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spp1=spark.createDataFrame(pd.DataFrame(usr_Struct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-----------+----------------------------+-------------------+\n",
      "|id |name  |last  |is_customer|phone                       |update             |\n",
      "+---+------+------+-----------+----------------------------+-------------------+\n",
      "|1  |asfand|saeed |true       |{+92329677783, +92342454672}|2022-04-12 04:10:00|\n",
      "|2  |saeed |asfand|true       |{+92329622283, +92342442312}|2021-04-11 04:10:00|\n",
      "|3  |ali   |khan  |false      |{+92329644483, +92342445552}|2021-04-22 12:10:00|\n",
      "|4  |khan  |syed  |false      |{null, null}                |null               |\n",
      "+---+------+------+-----------+----------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spp1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method select in module pyspark.sql.dataframe:\n",
      "\n",
      "select(*cols) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Projects a set of expressions and returns a new :class:`DataFrame`.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    cols : str, :class:`Column`, or list\n",
      "        column names (string) or expressions (:class:`Column`).\n",
      "        If one of the column names is '*', that column is expanded to include all columns\n",
      "        in the current :class:`DataFrame`.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df.select('*').collect()\n",
      "    [Row(age=2, name='Alice'), Row(age=5, name='Bob')]\n",
      "    >>> df.select('name', 'age').collect()\n",
      "    [Row(name='Alice', age=2), Row(name='Bob', age=5)]\n",
      "    >>> df.select(df.name, (df.age + 10).alias('age')).collect()\n",
      "    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(spp1.select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-----------+----------------------------+-------------------+\n",
      "|id |name  |last  |is_customer|phone                       |update             |\n",
      "+---+------+------+-----------+----------------------------+-------------------+\n",
      "|1  |asfand|saeed |true       |{+92329677783, +92342454672}|2022-04-12 04:10:00|\n",
      "|2  |saeed |asfand|true       |{+92329622283, +92342442312}|2021-04-11 04:10:00|\n",
      "|3  |ali   |khan  |false      |{+92329644483, +92342445552}|2021-04-22 12:10:00|\n",
      "|4  |khan  |syed  |false      |{null, null}                |null               |\n",
      "+---+------+------+-----------+----------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spp1.select ('*').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-----------+--------------------+-------------------+------------+\n",
      "| id|  name|  last|is_customer|               phone|             update|       first|\n",
      "+---+------+------+-----------+--------------------+-------------------+------------+\n",
      "|  1|asfand| saeed|       true|{+92329677783, +9...|2022-04-12 04:10:00|+92329677783|\n",
      "|  2| saeed|asfand|       true|{+92329622283, +9...|2021-04-11 04:10:00|+92329622283|\n",
      "|  3|   ali|  khan|      false|{+92329644483, +9...|2021-04-22 12:10:00|+92329644483|\n",
      "|  4|  khan|  syed|      false|        {null, null}|               null|        null|\n",
      "+---+------+------+-----------+--------------------+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spp1.select ('*',col('phone.first')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-----------+--------------------+-------------------+\n",
      "| id|  name|  last|is_customer|               phone|             update|\n",
      "+---+------+------+-----------+--------------------+-------------------+\n",
      "|  1|asfand| saeed|       true|{+92329677783, +9...|2022-04-12 04:10:00|\n",
      "|  2| saeed|asfand|       true|{+92329622283, +9...|2021-04-11 04:10:00|\n",
      "|  3|   ali|  khan|      false|{+92329644483, +9...|2021-04-22 12:10:00|\n",
      "|  4|  khan|  syed|      false|        {null, null}|               null|\n",
      "+---+------+------+-----------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spp1.alias('u').select('u.*').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----------+\n",
      "| id|  name|is_customer|\n",
      "+---+------+-----------+\n",
      "|  1|asfand|       true|\n",
      "|  2| saeed|       true|\n",
      "|  3|   ali|      false|\n",
      "|  4|  khan|      false|\n",
      "+---+------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## col is used when you have to apply function on columns\n",
    "spp1.alias('u').select(['u.id','u.name',col('is_customer')]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,lit,concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|    full_name|\n",
      "+-------------+\n",
      "|asfand, saeed|\n",
      "|saeed, asfand|\n",
      "|    ali, khan|\n",
      "|   khan, syed|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spp1.alias('u').select (concat (col('name'),lit(', '),col('last')).alias('full_name')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SelectExpr on Spark Data Frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method selectExpr in module pyspark.sql.dataframe:\n",
      "\n",
      "selectExpr(*expr) method of pyspark.sql.dataframe.DataFrame instance\n",
      "    Projects a set of SQL expressions and returns a new :class:`DataFrame`.\n",
      "    \n",
      "    This is a variant of :func:`select` that accepts SQL expressions.\n",
      "    \n",
      "    .. versionadded:: 1.3.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df.selectExpr(\"age * 2\", \"abs(age)\").collect()\n",
      "    [Row((age * 2)=4, abs(age)=2), Row((age * 2)=10, abs(age)=5)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(spp1.selectExpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+-----------+----------------------------+-------------------+\n",
      "|id |name  |last  |is_customer|phone                       |update             |\n",
      "+---+------+------+-----------+----------------------------+-------------------+\n",
      "|1  |asfand|saeed |true       |{+92329677783, +92342454672}|2022-04-12 04:10:00|\n",
      "|2  |saeed |asfand|true       |{+92329622283, +92342442312}|2021-04-11 04:10:00|\n",
      "|3  |ali   |khan  |false      |{+92329644483, +92342445552}|2021-04-22 12:10:00|\n",
      "|4  |khan  |syed  |false      |{null, null}                |null               |\n",
      "+---+------+------+-----------+----------------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## We use the \n",
    "spp1.alias('u').selectExpr('u.*').show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,lit,concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| id|    full_name|\n",
      "+---+-------------+\n",
      "|  1|asfand, saeed|\n",
      "|  2|saeed, asfand|\n",
      "|  3|    ali, khan|\n",
      "|  4|   khan, syed|\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spp1.alias('u').selectExpr('id',\"concat(name, ', ',last ) as full_name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "spp1.createOrReplaceTempView('users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| id|    full_name|\n",
      "+---+-------------+\n",
      "|  1|asfand, saeed|\n",
      "|  2|saeed, asfand|\n",
      "|  3|    ali, khan|\n",
      "|  4|   khan, syed|\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select id,concat(name, ', ' ,last ) as full_name from users\n",
    "          \n",
    "          \"\"\"\n",
    "          ).\\\n",
    "              show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Columns Using Spark Data Frame Names**\n",
    "* spp1['id'] and col('id') will return column type object.\n",
    "* We can't use col() as selectExpr, We can pass strings only we cant pass col type objects as we did in past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'id'>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spp1['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'id'>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.column.Column"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spp1['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spp1.select(spp1['id']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "| id|  name|\n",
      "+---+------+\n",
      "|  1|asfand|\n",
      "|  2| saeed|\n",
      "|  3|   ali|\n",
      "|  4|  khan|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spp1.select(spp1['id'],col('name')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'u' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Asfandyar\\Desktop\\python_Asfandyar\\40 days\\chilla\\Spark\\Certification Spark\\Spark2.ipynb Cell 28'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Asfandyar/Desktop/python_Asfandyar/40%20days/chilla/Spark/Certification%20Spark/Spark2.ipynb#ch0000165?line=0'>1</a>\u001b[0m spp1\u001b[39m.\u001b[39malias(\u001b[39m'\u001b[39m\u001b[39mu\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mselect(u[\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'u' is not defined"
     ]
    }
   ],
   "source": [
    "## \n",
    "spp1.alias('u').select(u['id']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------+\n",
      "| id|  name|  last|\n",
      "+---+------+------+\n",
      "|  1|asfand| saeed|\n",
      "|  2| saeed|asfand|\n",
      "|  3|   ali|  khan|\n",
      "|  4|  khan|  syed|\n",
      "+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spp1.alias('u').select('u.id',col('name'),'last').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spp1.selectExpr(col('id'),'name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| id|         full|\n",
      "+---+-------------+\n",
      "|  1|asfand, saeed|\n",
      "|  2|saeed, asfand|\n",
      "|  3|    ali, khan|\n",
      "|  4|   khan, syed|\n",
      "+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spp1.alias('u').selectExpr('u.id',\"concat(u.name, ', ',u.last) as full\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "spp1.createOrReplaceTempView('users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+\n",
      "| id|    full_name|\n",
      "+---+-------------+\n",
      "|  1|asfand, saeed|\n",
      "|  2|saeed, asfand|\n",
      "|  3|    ali, khan|\n",
      "|  4|   khan, syed|\n",
      "+---+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 64191)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Asfandyar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"c:\\Users\\Asfandyar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"c:\\Users\\Asfandyar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"c:\\Users\\Asfandyar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"c:\\Users\\Asfandyar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\accumulators.py\", line 262, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"c:\\Users\\Asfandyar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\accumulators.py\", line 235, in poll\n",
      "    if func():\n",
      "  File \"c:\\Users\\Asfandyar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\accumulators.py\", line 239, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"c:\\Users\\Asfandyar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\serializers.py\", line 562, in read_int\n",
      "    length = stream.read(4)\n",
      "  File \"c:\\Users\\Asfandyar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "          select id,concat(u.name,', ', u.last) as full_name\n",
    "          from users as u\n",
    "          '''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd044dfe803f410830d2077cd20a7505658c0f80bea76037d58d809c64c95f16"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
